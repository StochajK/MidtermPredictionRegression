{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3d7cfe",
   "metadata": {},
   "source": [
    "# Midterm Election Regression Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad2eac",
   "metadata": {},
   "source": [
    "The goal is to use regression techniques to compare how inflation, job growth, voter turnout, and presidential approval ratings might correlate to or influence the outcome of a midterm election, in how many senate and house seats flipped to another policial party. We hope that by the end of the project, we can know which factors have more of an effect on the outcome of a midterm, and can use the model to predict how a new midterm will fare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f327b",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a8b911",
   "metadata": {},
   "source": [
    "Because we are getting the data from different datasets, we needed to clean each dataset individually to get the information we wanted before we could add it to one central dataframe to house all of the information. \n",
    "\n",
    "To easier add out data frame to the same pandas dataframe, we are going to take each of the variable csv files and clean them so we get dataframes with two columns, one for the year and one for the variable. For example, the inflation data will have a column['Year'] that includes every midterm year of avaliable data, and a column ['CPI % change May-Oct'] that houses percent change in CPI for six months before the election date of the given year. \n",
    "\n",
    "Once cleaned, we will perform pd.merge to combine the datasets into one, that houses the election year and all the important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95932a",
   "metadata": {},
   "source": [
    "## Where the Data comes from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d80ac5",
   "metadata": {},
   "source": [
    "We get the [Midterm Election](https://www.presidency.ucsb.edu/statistics/data/seats-congress-gainedlost-the-presidents-party-mid-term-elections) data, including presidential party, president, president approval ratings, seats to defend, and seats won or lost from the American Presidency Project. This includes information beginning with FDR in 1934. \n",
    "\n",
    "We get the [inflation data](https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SA0;jsessionid=04BF074AA2F02CAFB14656118D04709A) from the Bureau of Labor Statistics. We will take the October data from a midterm year showing the % change in CPI over the past six month period. This will give us a good sense of how voters were perceiving and experiencing inflation leading up to the voting date. \n",
    "\n",
    "We get the [voter turnout](https://www.census.gov/data/tables/time-series/demo/voting-and-registration/voting-historical-time-series.html) data by dividing the sum of the population that voted in each state by the total US population. These datasets are taken from the US Census. \n",
    "\n",
    "\n",
    "We get the [job growth](https://seidmaninstitute.com/job-growth/year/) data by iterating through the years to find % change of job growth within the years of the election. This data takes the Jan information from every year. This will provide some implication for how an increase or decrease in employment opportunities may impact election results. \n",
    "\n",
    "All these data sources are validated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191662a",
   "metadata": {},
   "source": [
    "## Cleaning Inflation Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156dbbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f601b66c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>CPI % change may-oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1966</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1970</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1974</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1978</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1982</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1986</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1994</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  CPI % change may-oct\n",
       "0   1946                  13.0\n",
       "1   1950                   4.2\n",
       "2   1954                   0.0\n",
       "3   1958                   0.0\n",
       "4   1962                   0.7\n",
       "5   1966                   1.9\n",
       "6   1970                   2.3\n",
       "7   1974                   6.5\n",
       "8   1978                   5.0\n",
       "9   1982                   3.5\n",
       "10  1986                   1.6\n",
       "11  1990                   3.6\n",
       "12  1994                   1.4\n",
       "13  1998                   0.9\n",
       "14  2002                   0.8\n",
       "15  2006                   0.1\n",
       "16  2010                   0.3\n",
       "17  2014                   0.2\n",
       "18  2018                   0.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inflation Data\n",
    "#import the large dataset from the inflation csv\n",
    "df_inflation_big = pd.read_csv('inflation_data.csv')\n",
    "\n",
    "#to only keep October data, identify partial strings (Months) that need to be discarded\n",
    "discard = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', \n",
    "          'Sep', 'Nov', 'Dec']\n",
    "  \n",
    "# drop rows that contain the partial strings above \n",
    "#https://www.geeksforgeeks.org/how-to-drop-rows-that-contain-a-specific-string-in-pandas/\n",
    "df_infl_oct = df_inflation_big[~df_inflation_big.Label.str.contains('|'.join(discard))]\n",
    "\n",
    "#grab every fourth year (midterm years) into new df\n",
    "df_infl_midterms = df_infl_oct.iloc[::4,:]\n",
    "\n",
    "#reset the indecies to start from 0\n",
    "#https://pynative.com/pandas-reset-index/\n",
    "df_infl_midterms.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#make the final dataframe of only the necessary columns (year and inflaiton percent change)\n",
    "df_inflation = df_infl_midterms[['Year', '6-Month % Change']].copy()\n",
    "\n",
    "#rename the percent change column to be more easily identifiable\n",
    "df_inflation.rename(columns = {'6-Month % Change': 'CPI % change may-oct'}, inplace=True)\n",
    "\n",
    "df_inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d02437",
   "metadata": {},
   "source": [
    "## Clean voter turnout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33c449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>% voter turnout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>50.137371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>40.754838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>44.160616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006</td>\n",
       "      <td>43.506701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>42.135092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998</td>\n",
       "      <td>41.884619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1994</td>\n",
       "      <td>45.042479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1990</td>\n",
       "      <td>45.022097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1986</td>\n",
       "      <td>45.977808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1982</td>\n",
       "      <td>48.519814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1978</td>\n",
       "      <td>45.763311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1974</td>\n",
       "      <td>43.908898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  % voter turnout\n",
       "0   2018        50.137371\n",
       "1   2014        40.754838\n",
       "2   2010        44.160616\n",
       "3   2006        43.506701\n",
       "4   2002        42.135092\n",
       "5   1998        41.884619\n",
       "6   1994        45.042479\n",
       "7   1990        45.022097\n",
       "8   1986        45.977808\n",
       "9   1982        48.519814\n",
       "10  1978        45.763311\n",
       "11  1974        43.908898"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOTE = \"VoterTurnoutData.csv\"\n",
    "POP  = \"PopulationData.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def clean_voters(filename):\n",
    "    # read in the csv file as the dataframe\n",
    "    df_voters = pd.read_csv(filename, skiprows = 3)\n",
    "    \n",
    "    # for our purposes, whether we use total or citizen data is unimportant, as\n",
    "    # we are examining trends, so we just have to stay consistent - I chose total\n",
    "    \n",
    "    # first, set the headers to be citizen or total and drop citizen cols\n",
    "    df_voters.columns = df_voters.iloc[1]\n",
    "    df_voters.drop(\"Citizen\", axis = 1, inplace = True)\n",
    "   \n",
    "    # change the column header to year, as this is more descriptive\n",
    "    df_voters.columns = df_voters.iloc[0]\n",
    "    \n",
    "    # drop duplicated and empty rows\n",
    "    df_voters.drop([0, 1, 2], axis = 0, inplace= True)\n",
    "    \n",
    "    # change the indexes to the name of the states\n",
    "    df_voters.set_index(\"State\", inplace = True)\n",
    "\n",
    "    return df_voters\n",
    "\n",
    "\n",
    "def clean_pop(filename):\n",
    "    # read inthe csv file as the dataframe\n",
    "    df_pop = pd.read_csv(filename, skiprows = 4)\n",
    "    \n",
    "    # drop the \"Fips\" column\n",
    "    df_pop.drop(\"Fips\", axis = 1, inplace = True)\n",
    "    \n",
    "    # make the areas the indexes\n",
    "    df_pop.set_index(\"Area Name\", inplace = True)\n",
    "    \n",
    "    return df_pop\n",
    "    \n",
    "\n",
    "def get_grand_avg(pct_lst, n_lst):\n",
    "    \n",
    "    total_voters = 0\n",
    "    for i in range(len(pct_lst)):\n",
    "        total_voters += pct_lst[i] * n_lst[i]\n",
    "        \n",
    "    total_pop = sum(n_lst)\n",
    "    \n",
    "    grand_avg = (total_voters / total_pop)\n",
    "    return(grand_avg)\n",
    "\n",
    "def get_year_data(df_vote, df_pop, year):\n",
    "    pct_lst = []\n",
    "    pop_lst = []\n",
    "    \n",
    "    vote_locs = df_vote.index\n",
    "    for state in vote_locs:\n",
    "        if not pd.isna(df_vote.loc[state, str(year)]):\n",
    "            pct_lst.append(float(df_vote.loc[state, str(year)]))\n",
    "            pop_lst.append(int((df_pop.loc[state, str(year)]).replace(\",\", \"\")))\n",
    "        \n",
    "    avg = get_grand_avg(pct_lst, pop_lst)\n",
    "    return avg\n",
    "        \n",
    "    \n",
    "\n",
    "# get the cleaned DataFrames\n",
    "df_pop = clean_pop(POP)\n",
    "df_voters = clean_voters(VOTE)\n",
    "    \n",
    "    \n",
    "# create the desired dataframe\n",
    "voter_dict = {\"Year\": [], \"% voter turnout\": []}\n",
    "    \n",
    "for year in df_voters.columns:\n",
    "    voter_dict[\"Year\"].append(int(year))\n",
    "    voter_dict[\"% voter turnout\"].append(get_year_data(df_voters, df_pop, year))\n",
    "    \n",
    "    \n",
    "    df_voter_turnout = pd.DataFrame(voter_dict)\n",
    "\n",
    "df_voter_turnout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef0856",
   "metadata": {},
   "source": [
    "## Clean job growth data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9266623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KASto\\AppData\\Local\\Temp\\ipykernel_19896\\1373123850.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_job_growth.rename(columns = {'% Change': 'Job Growth % change past year'}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Job Growth % change past year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1942</td>\n",
       "      <td>11.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1946</td>\n",
       "      <td>-4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>-2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1954</td>\n",
       "      <td>-1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>-1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1962</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1966</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1970</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1974</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1978</td>\n",
       "      <td>4.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1982</td>\n",
       "      <td>-0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1986</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1990</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1994</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1998</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2002</td>\n",
       "      <td>-1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010</td>\n",
       "      <td>-3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Job Growth % change past year\n",
       "0   1942                          11.45\n",
       "1   1946                          -4.90\n",
       "2   1950                          -2.68\n",
       "3   1954                          -1.42\n",
       "4   1958                          -1.56\n",
       "5   1962                           2.16\n",
       "6   1966                           5.07\n",
       "7   1970                           2.53\n",
       "8   1974                           3.26\n",
       "9   1978                           4.91\n",
       "10  1982                          -0.57\n",
       "11  1986                           2.47\n",
       "12  1990                           1.73\n",
       "13  1994                           2.53\n",
       "14  1998                           2.86\n",
       "15  2002                          -1.37\n",
       "16  2006                           1.99\n",
       "17  2010                          -3.20\n",
       "18  2014                           1.81\n",
       "19  2018                           1.42\n",
       "20  2022                           4.63"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the csv files \n",
    "df_jobs = pd.read_csv('US_jobs.csv')\n",
    "\n",
    "# cleaned data for visualization\n",
    "df_job_change = df_jobs[['Year', '% Change']]\n",
    "\n",
    "# list of years of election\n",
    "election_years = [1934, 1938, 1942, 1946, 1950, 1954, 1958, 1962, 1966, 1970, 1974, \n",
    "                  1978, 1982, 1986, 1990, 1994, 1998, 2002, 2006, 2010, 2014, 2018, 2022]\n",
    "\n",
    "# initialize list for new data on important years\n",
    "new_data = []\n",
    "\n",
    "# filter to all the years of the election by accessing the 'year' column\n",
    "df_job_growth = df_job_change.loc[df_job_change['Year'].isin(election_years)]\n",
    "         \n",
    "#reset the indecies to start from 0 of new dataframe\n",
    "df_job_growth.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#rename the percent change column to be more easily identifiable\n",
    "df_job_growth.rename(columns = {'% Change': 'Job Growth % change past year'}, inplace=True)\n",
    "\n",
    "\n",
    "df_job_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d1098",
   "metadata": {},
   "source": [
    "## Cleaning midterm election data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72872e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'midterm_data_copy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19896\\880806477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use pandas read_csv to read in the midterm data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_midterm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'midterm_data_copy.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# create a list of all the columns we want to drop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m to_drop = ['Lame Duck?','Approval Early Aug','Approval Late Aug','Approval Early Sep',\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1219\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'midterm_data_copy.csv'"
     ]
    }
   ],
   "source": [
    "# use pandas read_csv to read in the midterm data\n",
    "df_midterm = pd.read_csv('midterm_data_copy.csv')\n",
    "\n",
    "# create a list of all the columns we want to drop\n",
    "to_drop = ['Lame Duck?','Approval Early Aug','Approval Late Aug','Approval Early Sep',\n",
    "          'Approval Late Sep']\n",
    "\n",
    "df_midterm.drop(to_drop, inplace=True, axis=1)\n",
    "\n",
    "df_midterm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90007f56",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "We keep the october approval ratings because we plan on using the approval ratings in our prediction and feature importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92defc8",
   "metadata": {},
   "source": [
    "## Combining the data into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the inflation dataset to the midterm dataset\n",
    "df_midterm = df_midterm.merge(df_inflation, on='Year', how='left')\n",
    "\n",
    "#merge the voter turnout dataset to the midterm dataset\n",
    "df_midterm = df_midterm.merge(df_voter_turnout, on='Year', how='left')\n",
    "\n",
    "#merge the job growth dataset to the midterm dataset \n",
    "df_midterm = df_midterm.merge(df_job_growth, on='Year', how='left')\n",
    "\n",
    "df_midterm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b683878",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e79b0",
   "metadata": {},
   "source": [
    "## Visualization 1: Clustered Bar Chart Showing Midterm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df92643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# create a subplot\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "\n",
    "# to create an accurate cluster bar chart, make x the length of df_midterm\n",
    "x = np.arange(len(df_midterm))\n",
    "width = 0.3\n",
    "\n",
    "plt.gcf().set_size_inches(20, 15)\n",
    "\n",
    "# create our y values\n",
    "y0 = df_midterm['House Seats to defend']\n",
    "y1 = df_midterm['House Seats to defend'] + df_midterm['Seat Change, House Seats']\n",
    "y2 = df_midterm['Senate Seats to defend']\n",
    "y3 = df_midterm['Senate Seats to defend'] + df_midterm['Seat Change, Senate Seats']\n",
    "\n",
    "# initialize two counters\n",
    "n = 0\n",
    "m = 0\n",
    "\n",
    "# go through row and graph based on presidential party\n",
    "for idx in df_midterm.index:\n",
    "    \n",
    "    if df_midterm[\"President's party\"][idx] == 'R':\n",
    "        n += 1 \n",
    "        ax1.bar(x[idx]-0.3, y0[idx], width, color='brown', \n",
    "                label ='Republican seats to defend' if n == 1 else '')\n",
    "        ax1.bar(x[idx], y1[idx], width, color='orangered', \n",
    "                label = 'Change in Republican seats' if n == 1 else '')\n",
    "        ax2.bar(x[idx]-0.3, y2[idx], width, color='brown')\n",
    "        ax2.bar(x[idx], y3[idx], width, color='orangered')\n",
    "    \n",
    "    if df_midterm[\"President's party\"][idx] == 'D':\n",
    "        m += 1\n",
    "        ax1.bar(x[idx]-0.3, y0[idx], width, color='navy', \n",
    "                label ='Democratic seats to defend' if m == 1 else '')\n",
    "        ax1.bar(x[idx], y1[idx], width, color='blue', \n",
    "                label = 'Change in Democratic seats' if m == 1 else '')\n",
    "        ax2.bar(x[idx]-0.3, y2[idx], width, color='navy')\n",
    "        ax2.bar(x[idx], y3[idx], width, color='blue')\n",
    "\n",
    "\n",
    "ax1.set_xticks(x-0.1)\n",
    "ax1.set_xticklabels(df_midterm['Year'])\n",
    "ax2.set_xticks(x-0.1)\n",
    "ax2.set_xticklabels(df_midterm['Year'])\n",
    "ax1.set_title('House')\n",
    "ax2.set_title('Senate')\n",
    "fig.legend()\n",
    "\n",
    "plt.suptitle('Presidential Midterm Results')\n",
    "plt.xlabel(\"Year of Midterm\")\n",
    "ax1.set(ylabel = 'House seats')\n",
    "ax2.set(ylabel = 'Senate seats')\n",
    "plt.savefig('clean-midterm-data.png', edgecolor='black', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015de819",
   "metadata": {},
   "source": [
    "## Visualization 2: Line Chart of Inflation, Job Growth, and Voter Turnout in Election Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd09a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x=\"Year\", y=[\"\", \"\", \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae666c",
   "metadata": {},
   "source": [
    "# Data Analysis Plan "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a601acb",
   "metadata": {},
   "source": [
    "Our hope for this project is that we are able to perform factor importance analysis on the data we gather to see which is more important for determining the outcome of a midterm election. To do this, we think using regression models on each of the categories makes the most logical sense, because we want to see a predictions made from the data. We assume that random forest regressions will work the best, but we are going to try different kinds to see what provides us the strongest output. \n",
    "\n",
    "We also want our model to have a predictive factor, which we think using logarithmic regression model will aid in. We will compute the MSE score, and the R2 value (using SK learn), in order to help explain the correlation between values and at how accurate our regression is at predicting outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad129a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
